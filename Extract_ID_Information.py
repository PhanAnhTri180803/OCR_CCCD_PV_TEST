# -*- coding: utf-8 -*-
"""
OCR CCCD - Phi√™n b·∫£n c·∫£i ti·∫øn v·ªõi spell correction
- S·ª≠a l·ªói ch√≠nh t·∫£ t·ª´ OCR
- T√°ch c√°c tr∆∞·ªùng b·ªã d√≠nh nhau
- Tr√≠ch xu·∫•t ƒë·∫ßy ƒë·ªß t·∫•t c·∫£ th√¥ng tin
- Cho ph√©p ng∆∞·ªùi d√πng ch·ªçn file ·∫£nh
"""
import os, re, cv2, pytesseract, numpy as np
from pytesseract import Output
from collections import defaultdict
import tkinter as tk
from tkinter import filedialog

# ========== C·∫§U H√åNH ==========
TESS_CMD = r"C:\Program Files\Tesseract-OCR\tesseract.exe"
TESSDATA_PREFIX = r"C:\Program Files\Tesseract-OCR\tessdata"

pytesseract.pytesseract.tesseract_cmd = TESS_CMD
os.environ['TESSDATA_PREFIX'] = TESSDATA_PREFIX

# ========== B·∫¢NG MAP CHO S·ªê ==========
DIGIT_MAP = {
    'O': '0', 'o': '0', 'Q': '0', 'D': '0',
    'I': '1', 'l': '1', '|': '1', '!': '1', 'i': '1', 'J': '1',
    'Z': '2', 'z': '2',
    'E': '3', 'e': '3',
    'A': '4', 'h': '4',
    'S': '5', 's': '5',
    'G': '6', 'b': '6',
    'T': '7', 't': '7',
    'B': '8', 'R': '8',
    'g': '9', 'q': '9', 'P': '9'
}

# ========== SPELL CORRECTION MAP ==========
SPELL_CORRECTIONS = {
    's√°': 'S·ªë', 's√≥': 'S·ªë', 's·ªë': 'S·ªë', 's√¥': 'S·ªë',
    'H·ªç v√† t√™n': 'H·ªç v√† t√™n', 'H·ªç va t√™n': 'H·ªç v√† t√™n', 'Ho va ten': 'H·ªç v√† t√™n',
    'Ng√†y sinh': 'Ng√†y sinh', 'Ngay sinh': 'Ng√†y sinh', 'Ng√°y sinh': 'Ng√†y sinh',
    'Dateofbirth': 'Ng√†y sinh', 'Date of birth': 'Ng√†y sinh',
    'Gi·ªõit√≠nh': 'Gi·ªõi t√≠nh', 'Gioi tinh': 'Gi·ªõi t√≠nh', 'Gi√≥i t√≠nh': 'Gi·ªõi t√≠nh',
    'Qu·ªëct·ªãch': 'Qu·ªëc t·ªãch', 'Quoc tich': 'Qu·ªëc t·ªãch', 'Qu·ªëc tich': 'Qu·ªëc t·ªãch',
    'Nationality': 'Qu·ªëc t·ªãch', 'Nafionalty': 'Qu·ªëc t·ªãch', 'Nationlity': 'Qu·ªëc t·ªãch',
    'Qu√™ qu√°n': 'Qu√™ qu√°n', 'Que quan': 'Qu√™ qu√°n', 'Qu√™ quan': 'Qu√™ qu√°n',
    'N·ªùi th∆∞·ªùng tr√∫': 'N∆°i th∆∞·ªùng tr√∫', 'Noi thuong tru': 'N∆°i th∆∞·ªùng tr√∫',
    'N∆°i thu·ªùng tr√∫': 'N∆°i th∆∞·ªùng tr√∫', 'N∆°i th∆∞·ªùng tru': 'N∆°i th∆∞·ªùng tr√∫',
    'ƒê·ªãa ch·ªâ': 'N∆°i th∆∞·ªùng tr√∫', 'Dia chi': 'N∆°i th∆∞·ªùng tr√∫'
}

def correct_spelling(text):
    """S·ª≠a l·ªói ch√≠nh t·∫£ c∆° b·∫£n"""
    if not text:
        return text
    
    result = text
    for wrong, correct in SPELL_CORRECTIONS.items():
        result = re.sub(r'\b' + re.escape(wrong) + r'\b', correct, result, flags=re.IGNORECASE)
    
    return result

def normalize_to_digits(s):
    """Chuy·ªÉn ƒë·ªïi chu·ªói c√≥ th·ªÉ nh·∫ßm th√†nh s·ªë"""
    if not s:
        return ""
    result = ''.join(DIGIT_MAP.get(ch, ch) for ch in s)
    result = re.sub(r'[^0-9]', '', result)
    return result

# ========== TI·ªÜN √çCH ==========
def safe_mean(values):
    """T√≠nh trung b√¨nh an to√†n"""
    valid = [v for v in values if v >= 0]
    return float(np.mean(valid)) if valid else 0.0

def count_vietnamese_chars(text):
    """ƒê·∫øm k√Ω t·ª± ti·∫øng Vi·ªát c√≥ d·∫•u"""
    if not text:
        return 0
    vietnamese_chars = (
        '√†√°·∫°·∫£√£√¢·∫ß·∫•·∫≠·∫©·∫´ƒÉ·∫±·∫Ø·∫∑·∫≥·∫µ'
        '√®√©·∫π·∫ª·∫Ω√™·ªÅ·∫ø·ªá·ªÉ·ªÖ'
        '√¨√≠·ªã·ªâƒ©'
        '√≤√≥·ªç·ªè√µ√¥·ªì·ªë·ªô·ªï·ªó∆°·ªù·ªõ·ª£·ªü·ª°'
        '√π√∫·ª•·ªß≈©∆∞·ª´·ª©·ª±·ª≠·ªØ'
        '·ª≥√Ω·ªµ·ª∑·ªπ'
        'ƒë'
    )
    vietnamese_chars += vietnamese_chars.upper()
    return sum(1 for c in text if c in vietnamese_chars)

# ========== CH·ªåN FILE ·∫¢NH ==========
def select_image_file():
    """M·ªü h·ªôp tho·∫°i ch·ªçn file ·∫£nh"""
    root = tk.Tk()
    root.withdraw()  # ·∫®n c·ª≠a s·ªï ch√≠nh
    file_path = filedialog.askopenfilename(
        title="Ch·ªçn ·∫£nh CCCD",
        filetypes=[("Image files", "*.jpg *.jpeg *.png *.bmp")]
    )
    return file_path

# ========== TI·ªÄN X·ª¨ L√ù ·∫¢NH ==========
def preprocess_ultimate(img):
    """Ti·ªÅn x·ª≠ l√Ω t·ªëi ∆∞u nh·∫•t cho CCCD"""
    if img is None:
        raise ValueError("·∫¢nh ƒë·∫ßu v√†o l√† None")
    
    if len(img.shape) == 3:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    else:
        gray = img.copy()
    
    h, w = gray.shape
    print(f"K√≠ch th∆∞·ªõc: {w}x{h} pixels")
    
    # 1. Denoise nh·∫π
    denoised = cv2.fastNlMeansDenoising(gray, h=4, templateWindowSize=7, searchWindowSize=21)
    
    # 2. TƒÉng ƒë·ªô s·∫Øc n√©t (unsharp mask)
    gaussian = cv2.GaussianBlur(denoised, (0, 0), 2.0)
    sharpened = cv2.addWeighted(denoised, 1.5, gaussian, -0.5, 0)
    
    # 3. CLAHE nh·∫π
    clahe = cv2.createCLAHE(clipLimit=1.5, tileGridSize=(8, 8))
    contrast = clahe.apply(sharpened)
    
    # 4. Adaptive threshold
    block_size = 25 if h < 800 else 31
    adaptive = cv2.adaptiveThreshold(
        contrast, 255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY,
        block_size, 2
    )
    
    print(f"   ‚úì Ho√†n t·∫•t (block_size={block_size})")
    
    return adaptive, contrast

# ========== OCR T·ªêI ∆ØU ==========
def ocr_ultimate(img_binary, img_gray):
    """OCR v·ªõi nhi·ªÅu config v√† ch·ªçn t·ªët nh·∫•t"""
    results = []
    
    configs = [
        ('VIE_PSM6_Binary', '--oem 3 --psm 6 -l vie', img_binary),
        ('VIE_PSM4_Binary', '--oem 3 --psm 4 -l vie', img_binary),
        ('VIE+ENG_PSM6_Binary', '--oem 3 --psm 6 -l vie+eng', img_binary),
        ('VIE+ENG_PSM4_Binary', '--oem 3 --psm 4 -l vie+eng', img_binary),
        ('VIE_PSM6_Gray', '--oem 3 --psm 6 -l vie', img_gray),
    ]
    
    print(f"\n   ƒêang ch·∫°y {len(configs)} config OCR...")
    
    for idx, (name, cfg, img_use) in enumerate(configs, 1):
        try:
            data = pytesseract.image_to_data(img_use, config=cfg, output_type=Output.DICT)
            raw_text = pytesseract.image_to_string(img_use, config=cfg)
            
            # S·ª≠a l·ªói ch√≠nh t·∫£
            raw_text = correct_spelling(raw_text)
            
            lines = rebuild_lines_smart(data)
            
            avg_conf = safe_mean([l['conf'] for l in lines])
            viet_count = count_vietnamese_chars(raw_text)
            text_length = len(raw_text.strip())
            
            score = avg_conf * 1.0 + viet_count * 5.0 + min(text_length / 100.0, 15.0)
            
            results.append({
                'name': name,
                'raw_text': raw_text,
                'lines': lines,
                'avg_conf': avg_conf,
                'viet_count': viet_count,
                'score': score,
                'data': data
            })
            
            print(f"      [{idx}/{len(configs)}] {name:25s} | Conf: {avg_conf:5.1f} | Score: {score:6.1f}")
            
        except Exception as e:
            print(f"      [{idx}/{len(configs)}] {name:25s} | ‚ùå L·ªói: {e}")
            continue
    
    if not results:
        raise Exception("T·∫•t c·∫£ config OCR ƒë·ªÅu th·∫•t b·∫°i!")
    
    best = max(results, key=lambda x: x['score'])
    print(f"\n   üèÜ Config t·ªët nh·∫•t: {best['name']}")
    
    return best, results

def rebuild_lines_smart(data):
    """Rebuild lines v·ªõi kho·∫£ng tr·∫Øng ch√≠nh x√°c"""
    n = len(data.get('text', []))
    lines_dict = defaultdict(list)
    
    for i in range(n):
        word = (data['text'][i] or '').strip()
        if not word:
            continue
        
        # S·ª≠a ch√≠nh t·∫£ t·ª´ng word
        word = correct_spelling(word)
        
        try:
            conf = float(data['conf'][i])
        except:
            conf = 0.0
        
        block = data.get('block_num', [0]*n)[i]
        par = data.get('par_num', [0]*n)[i]
        line = data.get('line_num', [0]*n)[i]
        word_num = data.get('word_num', [0]*n)[i]
        left = data.get('left', [0]*n)[i]
        width = data.get('width', [0]*n)[i]
        
        key = (block, par, line)
        lines_dict[key].append({
            'word': word,
            'conf': conf,
            'word_num': word_num,
            'left': left,
            'right': left + width
        })
    
    result_lines = []
    for key in sorted(lines_dict.keys()):
        words_list = sorted(lines_dict[key], key=lambda x: (x['word_num'], x['left']))
        
        # Gi·ªØ words c√≥ conf >= 3 ho·∫∑c c√≥ k√Ω t·ª± Vi·ªát
        filtered_words = []
        for w in words_list:
            if w['conf'] >= 3 or count_vietnamese_chars(w['word']) > 0:
                filtered_words.append(w)
        
        if not filtered_words:
            filtered_words = words_list
        
        line_text = ' '.join([w['word'] for w in filtered_words])
        line_conf = safe_mean([w['conf'] for w in filtered_words])
        
        if line_text.strip():
            result_lines.append({
                'text': line_text,
                'conf': line_conf
            })
    
    return result_lines

# ========== TR√çCH XU·∫§T C·∫¢I TI·∫æN ==========
def extract_id_number(lines, raw_text):
    """Tr√≠ch xu·∫•t s·ªë CCCD (12 ch·ªØ s·ªë) ho·∫∑c CMND (9 ch·ªØ s·ªë)"""
    full_text = "\n".join([l['text'] for l in lines]) + "\n" + raw_text
    
    # T√¨m d√≤ng c√≥ "S·ªë" ho·∫∑c "ID"
    id_lines = []
    for i, line in enumerate(lines):
        if re.search(r'(s·ªë|so|id|cccd|cmnd|no\.)', line['text'], re.IGNORECASE):
            id_lines.append(line['text'])
            if i + 1 < len(lines):
                id_lines.append(lines[i + 1]['text'])
    
    search_text = "\n".join(id_lines) if id_lines else full_text
    
    # T√¨m 12 ch·ªØ s·ªë (CCCD m·ªõi) ho·∫∑c 9 ch·ªØ s·ªë (CMND c≈©)
    patterns = [r'\b\d{12}\b', r'\b\d{9}\b']
    for pattern in patterns:
        matches = re.findall(pattern, search_text)
        if matches:
            return matches[0]
    
    # T√¨m s·ªë c√≥ th·ªÉ b·ªã nh·∫ßm
    tokens = re.findall(r'[0-9OIlQDSsBgJAhEeTtRPq|!iz]{9,15}', search_text)
    for token in tokens:
        normalized = normalize_to_digits(token)
        if len(normalized) in [9, 12]:
            return normalized
    
    return None

def extract_name(lines):
    """Tr√≠ch xu·∫•t h·ªç t√™n"""
    for i, line in enumerate(lines):
        text = line['text']
        text_lower = text.lower()
        
        if any(kw in text_lower for kw in ['h·ªç v√† t√™n', 'ho va ten', 'full name', 'name']):
            # L·∫•y d√≤ng ti·∫øp theo
            if i + 1 < len(lines):
                name = lines[i + 1]['text'].strip()
                name = re.sub(r'\s*:\s*$', '', name)
                if name and name.isupper() and not re.search(r'\d', name):
                    return name
            
            # L·∫•y sau d·∫•u :
            if ':' in text:
                name = text.split(':', 1)[1].strip()
                name = re.sub(r'\s*:\s*$', '', name)
                if name and not re.search(r'\d', name):
                    return name
    
    # Fallback: d√≤ng vi·∫øt hoa kh√¥ng c√≥ s·ªë
    for line in lines:
        text = line['text'].strip()
        text = re.sub(r'\s*:\s*$', '', text)
        if text and text.isupper() and not re.search(r'\d', text):
            words = text.split()
            if 2 <= len(words) <= 5:
                return text
    
    return None

def extract_dob(lines, raw_text):
    """Tr√≠ch xu·∫•t ng√†y sinh"""
    full_text = "\n".join([l['text'] for l in lines]) + "\n" + raw_text
    
    # T√¨m d√≤ng c√≥ "Ng√†y sinh"
    dob_lines = []
    for i, line in enumerate(lines):
        if re.search(r'(ng√†y sinh|ngay sinh|date.*birth|dob)', line['text'], re.IGNORECASE):
            dob_lines.append(line['text'])
            if i + 1 < len(lines):
                dob_lines.append(lines[i + 1]['text'])
    
    search_text = "\n".join(dob_lines) if dob_lines else full_text
    
    # Pattern: dd/mm/yyyy ho·∫∑c dd-mm-yyyy
    patterns = [
        r'(\d{1,2})\s*[/-]\s*(\d{1,2})\s*[/-]\s*(\d{4})',
        r'(\d{1,2})\s*[\.\s]\s*(\d{1,2})\s*[\.\s]\s*(\d{4})'
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, search_text)
        for match in matches:
            try:
                day = int(re.sub(r'\s', '', match[0]))
                month = int(re.sub(r'\s', '', match[1]))
                year = int(re.sub(r'\s', '', match[2]))
                
                if 1 <= day <= 31 and 1 <= month <= 12 and 1920 <= year <= 2025:
                    return f"{day:02d}/{month:02d}/{year:04d}"
            except:
                continue
    
    # Fallback v·ªõi normalize
    date_tokens = re.findall(r'[\dOIl\s/.\-]{8,20}', search_text)
    for token in date_tokens:
        mapped = ''.join(DIGIT_MAP.get(ch, ch) if ch in DIGIT_MAP else ch for ch in token)
        
        for pattern in patterns:
            match = re.search(pattern, mapped)
            if match:
                try:
                    day = int(match.group(1))
                    month = int(match.group(2))
                    year = int(match.group(3))
                    
                    if 1 <= day <= 31 and 1 <= month <= 12 and 1920 <= year <= 2025:
                        return f"{day:02d}/{month:02d}/{year:04d}"
                except:
                    continue
    
    return None

def extract_sex(lines, raw_text):
    """Tr√≠ch xu·∫•t gi·ªõi t√≠nh"""
    full_text = " ".join([l['text'] for l in lines]) + " " + raw_text
    full_text_lower = full_text.lower()

    patterns = [
        r'gi·ªõi t√≠nh\s*:\s*(nam|n·ªØ|nu|male|female)\b',
        r'sex\s*:\s*(nam|n·ªØ|nu|male|female)\b',
        r'gender\s*:\s*(nam|n·ªØ|nu|male|female)\b'
    ]

    for pattern in patterns:
        match = re.search(pattern, full_text_lower, re.IGNORECASE)
        if match:
            sex_value = match.group(1).strip().lower()
            if sex_value in ['nam', 'male']:
                return 'Nam'
            elif sex_value in ['n·ªØ', 'nu', 'female']:
                return 'N·ªØ'

    # Fallback
    if 'nam' in full_text_lower and 'vi·ªát nam' not in full_text_lower[:full_text_lower.find('nam') + 3]:
        return 'Nam'
    elif 'n·ªØ' in full_text_lower or 'nu' in full_text_lower:
        return 'N·ªØ'
    elif 'male' in full_text_lower:
        return 'Nam'
    elif 'female' in full_text_lower:
        return 'N·ªØ'

    return None

def extract_nation(lines, raw_text):
    """Tr√≠ch xu·∫•t qu·ªëc t·ªãch"""
    full_text = " ".join([l['text'] for l in lines]) + " " + raw_text
    full_text_lower = full_text.lower()

    patterns = [
        r'qu·ªëc t·ªãch\s*:\s*(vi·ªát nam|viet nam|vietnam|vn|vi·ªátnam)\b',
        r'nationality\s*:\s*(vi·ªát nam|viet nam|vietnam|vn|vi·ªátnam)\b'
    ]

    for pattern in patterns:
        match = re.search(pattern, full_text_lower, re.IGNORECASE)
        if match:
            return 'Vi·ªát Nam'

    if 'vi·ªát nam' in full_text_lower or 'viet nam' in full_text_lower or 'vietnam' in full_text_lower:
        return 'Vi·ªát Nam'

    for i, line in enumerate(lines):
        text = line['text']
        text_lower = text.lower()
        
        if 'qu·ªëc t·ªãch' in text_lower or 'nationality' in text_lower:
            if ':' in text:
                parts = text.split(':', 1)
                if len(parts) == 2:
                    nation = parts[1].strip()
                    nation = re.sub(r'[^\w\s√Ä-·ªπ]', ' ', nation).strip()
                    if nation and len(nation) >= 3:
                        return nation.capitalize()
            
            if i + 1 < len(lines):
                next_text = lines[i + 1]['text'].strip()
                if 'vi·ªát nam' in next_text.lower() or 'viet nam' in next_text.lower():
                    return 'Vi·ªát Nam'
                elif next_text and len(next_text) >= 3 and not re.search(r'\d{3,}', next_text):
                    return next_text.capitalize()
    
    return None

def extract_origin(lines):
    """Tr√≠ch xu·∫•t qu√™ qu√°n"""
    for i, line in enumerate(lines):
        text = line['text']
        text_lower = text.lower()
        
        if 'qu√™ qu√°n' in text_lower or 'place of origin' in text_lower:
            if ':' in text:
                parts = text.split(':', 1)
                if len(parts) == 2:
                    origin = parts[1].strip()
                    if origin and len(origin) > 5:
                        return origin
            
            if i + 1 < len(lines):
                next_text = lines[i + 1]['text'].strip()
                if next_text and len(next_text) > 5:
                    return next_text
    
    return None

def extract_address(lines):
    """Tr√≠ch xu·∫•t n∆°i th∆∞·ªùng tr√∫"""
    address_parts = []
    
    for i, line in enumerate(lines):
        text = line['text']
        text_lower = text.lower()
        
        keywords = ['n∆°i th∆∞·ªùng tr√∫', 'place of residence', 'th∆∞·ªùng tr√∫', 'ƒë·ªãa ch·ªâ', 'noi thuong tru']
        
        if any(kw in text_lower for kw in keywords):
            if ':' in text:
                parts = text.split(':', 1)
                if len(parts) == 2:
                    addr = parts[1].strip()
                    if addr and len(addr) > 3:
                        address_parts.append(addr)
            
            for j in range(i + 1, min(i + 10, len(lines))):
                next_text = lines[j]['text'].strip()
                
                stop_keywords = ['ng√†y', 'date', 'c√≥ gi√° tr·ªã', 'valid', 'gi·ªõi t√≠nh']
                if any(kw in next_text.lower() for kw in stop_keywords):
                    break
                
                if next_text and len(next_text) > 3:
                    if not re.match(r'^\d+$', next_text):
                        if re.search(r'[a-zA-Z√Ä-·ªπ]', next_text):
                            address_parts.append(next_text)
            
            break
    
    if address_parts:
        full_address = ', '.join(address_parts)
        full_address = re.sub(r',\s*,', ',', full_address)
        full_address = re.sub(r'\s+', ' ', full_address).strip(' ,')
        
        if len(full_address) >= 10:
            return full_address
    
    return None

# ========== MAIN ==========
def main():
    print("=" * 80)
    print(" OCR CCCD - TR√çCH XU·∫§T ƒê·∫¶Y ƒê·ª¶ & CH√çNH X√ÅC ".center(80, "="))
    print("=" * 80)
    
    # Ch·ªçn file ·∫£nh
    print("\nüìÇ Ch·ªçn file ·∫£nh...")
    image_path = select_image_file()
    if not image_path:
        raise SystemExit("‚ùå Kh√¥ng ch·ªçn file ·∫£nh n√†o!")
    
    # ƒê·ªçc ·∫£nh
    print(f"\nüìÇ ƒê·ªçc ·∫£nh: {image_path}")
    img = cv2.imread(image_path)
    if img is None:
        raise SystemExit(f"‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c: {image_path}")
    
    print(f"‚úì Th√†nh c√¥ng: {img.shape[1]}x{img.shape[0]} px")
    
    # Ti·ªÅn x·ª≠ l√Ω
    print("\nüîß Ti·ªÅn x·ª≠ l√Ω ·∫£nh...")
    img_binary, img_gray = preprocess_ultimate(img)
    
    cv2.imwrite("debug_final_binary.png", img_binary)
    cv2.imwrite("debug_final_gray.png", img_gray)
    print("‚úì L∆∞u: debug_final_binary.png, debug_final_gray.png")
    
    # OCR
    print("\nüîç OCR...")
    best_result, all_results = ocr_ultimate(img_binary, img_gray)
    
    # Hi·ªÉn th·ªã d√≤ng ƒë√£ s·ª≠a l·ªói
    print("\n" + "=" * 80)
    print(" C√ÅC D√íNG SAU KHI S·ª¨A L·ªñI CH√çNH T·∫¢ ".center(80, "="))
    print("=" * 80)
    for idx, line in enumerate(best_result['lines'], 1):
        print(f"[{idx:2d}] [{line['conf']:5.1f}] {line['text']}")
    
    # Tr√≠ch xu·∫•t
    print("\n" + "=" * 80)
    print(" TR√çCH XU·∫§T TH√îNG TIN ".center(80, "="))
    print("=" * 80)
    
    id_num = extract_id_number(best_result['lines'], best_result['raw_text'])
    name = extract_name(best_result['lines'])
    dob = extract_dob(best_result['lines'], best_result['raw_text'])
    sex = extract_sex(best_result['lines'], best_result['raw_text'])
    nation = extract_nation(best_result['lines'], best_result['raw_text'])
    origin = extract_origin(best_result['lines'])
    address = extract_address(best_result['lines'])
    
    # Fallback cho s·ªë CCCD
    if not id_num:
        print("\n‚ö†Ô∏è  Th·ª≠ OCR chuy√™n d·ª•ng cho s·ªë...")
        cfg = '--oem 3 --psm 7 -c tessedit_char_whitelist=0123456789'
        try:
            num_text = pytesseract.image_to_string(img_binary, config=cfg)
            num_text = normalize_to_digits(num_text)
            if 9 <= len(num_text) <= 12:
                id_num = num_text
                print(f"‚úì T√¨m th·∫•y: {id_num}")
        except:
            pass
    
    # Hi·ªÉn th·ªã k·∫øt qu·∫£
    print("\n" + "=" * 80)
    print(" K·∫æT QU·∫¢ CU·ªêI C√ôNG ".center(80, "="))
    print("=" * 80)
    
    print(f"\nüìá S·ªë CCCD/CMND    : {id_num or '‚ùå Kh√¥ng t√¨m th·∫•y'}")
    print(f"üë§ H·ªç v√† t√™n       : {name or '‚ùå Kh√¥ng t√¨m th·∫•y'}")
    print(f"üéÇ Ng√†y sinh       : {dob or '‚ùå Kh√¥ng t√¨m th·∫•y'}")
    print(f"‚öß  Gi·ªõi t√≠nh       : {sex or '‚ùå Kh√¥ng t√¨m th·∫•y'}")
    print(f"üåç Qu·ªëc t·ªãch       : {nation or '‚ùå Kh√¥ng t√¨m th·∫•y'}")
    print(f"üèò  Qu√™ qu√°n        : {origin or '‚ùå Kh√¥ng t√¨m th·∫•y'}")
    print(f"üè† N∆°i th∆∞·ªùng tr√∫  : {address or '‚ùå Kh√¥ng t√¨m th·∫•y'}")
    
    # Th·ªëng k√™
    success_count = sum([1 for x in [id_num, name, dob, sex, nation, origin, address] if x])
    print(f"\nüìä Tr√≠ch xu·∫•t: {success_count}/7 tr∆∞·ªùng")
    
    print("\n" + "=" * 80)
    print(" HO√ÄN T·∫§T ".center(80, "="))
    print("=" * 80 + "\n")

if __name__ == '__main__':
    main()